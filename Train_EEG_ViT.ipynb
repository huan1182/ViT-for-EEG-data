{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from linformer import Linformer\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from util import data_creator2,EEGDataset,Resize\n",
    "from vit_pytorch.efficient import ViT\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "interval=1250\n",
    "aug=2\n",
    "modelname='model_5s'\n",
    "inpath='data_in2'\n",
    "out_path='data_out4'\n",
    "out_path_F='data_out_F'\n",
    "num_file=np.int16(np.array([11,7,8,8]))\n",
    "num_file2=np.int16(np.array([19,16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27745493, 8)\n",
      "(27082764, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_creator2(inpath,out_path,num_file=num_file2,interval=interval,aug=aug,do_fft=False,stack_3_ch=False)\n",
    "#data_creator(inpath,out_path,num_file=num_file,interval=interval,aug=aug,do_fft=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model in time domain: Set up\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "device = get_device()\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)\n",
    "EEGtransforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Resize(224)\n",
    "])\n",
    "data_train = EEGDataset(os.path.join(\"data_out4\", \"train\"), transform=EEGtransforms)\n",
    "data_test = EEGDataset(os.path.join(\"data_out4\", \"test\"), transform=EEGtransforms)\n",
    "train_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  \n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")\n",
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=256,\n",
    "    patch_size=32,\n",
    "    num_classes=2,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=1,\n",
    ").to(device)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.4460 - acc: 0.7856 - val_loss : 0.3859 - val_acc: 0.8271\n",
      "tp : 18505 - fp : 4429 - tn: 17763 - fn : 3157 - tpr:0.8543- fpr: 0.1996\n",
      "\n",
      "Epoch : 2 - loss : 0.2374 - acc: 0.9003 - val_loss : 0.2595 - val_acc: 0.8912\n",
      "tp : 19560 - fp : 2670 - tn: 19522 - fn : 2102 - tpr:0.9030- fpr: 0.1203\n",
      "\n",
      "Epoch : 3 - loss : 0.1688 - acc: 0.9332 - val_loss : 0.2704 - val_acc: 0.8964\n",
      "tp : 20489 - fp : 3375 - tn: 18817 - fn : 1173 - tpr:0.9458- fpr: 0.1521\n",
      "\n",
      "Epoch : 4 - loss : 0.1318 - acc: 0.9496 - val_loss : 0.2402 - val_acc: 0.9057\n",
      "tp : 20296 - fp : 2768 - tn: 19424 - fn : 1366 - tpr:0.9369- fpr: 0.1247\n",
      "\n",
      "Epoch : 5 - loss : 0.1111 - acc: 0.9584 - val_loss : 0.3103 - val_acc: 0.8905\n",
      "tp : 20059 - fp : 3193 - tn: 18999 - fn : 1603 - tpr:0.9260- fpr: 0.1439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Time Domain Train Model\n",
    "best_val_acc = None\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    count=0\n",
    "    prob_0=None\n",
    "    #pred = None\n",
    "    for data, label in train_loader:\n",
    "        data = data.float().to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim = 1)\n",
    "        curr_prob_0=output[:,0]\n",
    "\n",
    "        #curr_pred = output.argmax(dim = 1)\n",
    "        #if pred:\n",
    "        #    pred = torch.cat(curr_pred.cpu().numpy())\n",
    "      #  else:\n",
    "       #     pred = curr_pred\n",
    "      #  pred = pred.numpy()\n",
    "        \n",
    "        acc = (pred == label).float().mean()\n",
    "        #curr_tp_count = (pred == 1) and (label == 1)\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        tp_count=0\n",
    "        fp_count=0\n",
    "        tn_count=0\n",
    "        fn_count=0\n",
    "        prob_1=None\n",
    "        whole_label=None\n",
    "        #best_val_acc=0\n",
    "        for data, label in test_loader:\n",
    "            #print(data.shape)\n",
    "            data = data.float().to(device)\n",
    "            label = label.to(device)\n",
    "                        \n",
    "            val_output = model(data)\n",
    "            pred=val_output.argmax(dim=1)\n",
    "            val_loss = criterion(val_output, label)\n",
    "            tp_count+=torch.logical_and(pred == 1, label == 1).sum()\n",
    "            fp_count+=torch.logical_and(pred == 1, label == 0).sum()\n",
    "            tn_count+=torch.logical_and(pred == 0, label == 0).sum()\n",
    "            fn_count+=torch.logical_and(pred == 0, label == 1).sum()\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(test_loader)\n",
    "            epoch_val_loss += val_loss / len(test_loader)\n",
    "            #curr_pred = val_output.argmax(dim = 1)\n",
    "            curr_prob_1=val_output[:,1]\n",
    "            if prob_1 == None:\n",
    "                \n",
    "                prob_1=curr_prob_1\n",
    "            else:\n",
    "                prob_1=torch.cat((prob_1,curr_prob_1))\n",
    "            if whole_label==None:\n",
    "                \n",
    "                whole_label=label\n",
    "            else:\n",
    "                whole_label=torch.cat((whole_label,label))\n",
    "        tpr=tp_count/(tp_count+fn_count)\n",
    "        fpr=fp_count/(tn_count+fp_count)\n",
    "        #tn=tn_count/(tn_count+fp_count)\n",
    "        #fn=fn_count/(tn_count+fn_count)            \n",
    "        if best_val_acc:\n",
    "            if best_val_acc < epoch_val_accuracy:\n",
    "                best_val_acc = epoch_val_accuracy\n",
    "                torch.save(model,\"model_Time.pt\")\n",
    "                optm_tpr=tp_count/(tp_count+fn_count)\n",
    "                optm_fpr=fp_count/(tn_count+fp_count)\n",
    "                optm_true_label=whole_label.cpu().numpy()\n",
    "                optm_prob_1=prob_1.cpu().numpy()\n",
    "                #optm_tn=tn_count/(fp_count+tn_count)\n",
    "                #optm_fn=fn_count/(tn_count+fn_count)\n",
    "        else:\n",
    "            best_val_acc = epoch_val_accuracy\n",
    "            torch.save(model,\"model_Time.pt\")\n",
    "            optm_tpr=tp_count/(tp_count+fn_count)\n",
    "            optm_fpr=fp_count/(fp_count+tn_count)\n",
    "            #optm_tn=tn_count/(tn_count+fn_count)\n",
    "            optm_true_label=whole_label.cpu().numpy()\n",
    "            optm_prob_1=prob_1.cpu().numpy()            \n",
    "        print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\"\n",
    "    )\n",
    "    print(f\"tp : {tp_count} - fp : {fp_count} - tn: {tn_count} - fn : {fn_count} - tpr:{tpr:.4f}- fpr: {fpr:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Domain\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Resize(224)\n",
    "])\n",
    "data_train2 = EEGDataset(os.path.join(\"data_out3\", \"train\"), transform=train_transforms)\n",
    "data_test2 = EEGDataset(os.path.join(\"data_out3\", \"test\"), transform=train_transforms)\n",
    "train_loader2 = DataLoader(dataset=data_train2, batch_size=batch_size, shuffle=True)\n",
    "test_loader2 = DataLoader(dataset=data_test2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "efficient_transformer = Linformer(\n",
    "    dim=128,\n",
    "    seq_len=49+1,  \n",
    "    depth=12,\n",
    "    heads=8,\n",
    "    k=64\n",
    ")\n",
    "model = ViT(\n",
    "    dim=128,\n",
    "    image_size=256,\n",
    "    patch_size=32,\n",
    "    num_classes=2,\n",
    "    transformer=efficient_transformer,\n",
    "    channels=1,\n",
    ").to(device)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 - loss : 0.6084 - acc: 0.6597 - val_loss : 0.5510 - val_acc: 0.7186\n",
      "tp : 15126 - fp : 5808 - tn: 16384 - fn : 6536 - tpr:0.6983- fpr: 0.2617\n",
      "\n",
      "Epoch : 2 - loss : 0.5328 - acc: 0.7265 - val_loss : 0.5240 - val_acc: 0.7334\n",
      "tp : 16237 - fp : 6273 - tn: 15919 - fn : 5425 - tpr:0.7496- fpr: 0.2827\n",
      "\n",
      "Epoch : 3 - loss : 0.4977 - acc: 0.7526 - val_loss : 0.5077 - val_acc: 0.7502\n",
      "tp : 16462 - fp : 5764 - tn: 16428 - fn : 5200 - tpr:0.7599- fpr: 0.2597\n",
      "\n",
      "Epoch : 4 - loss : 0.4631 - acc: 0.7740 - val_loss : 0.4708 - val_acc: 0.7721\n",
      "tp : 16043 - fp : 4373 - tn: 17819 - fn : 5619 - tpr:0.7406- fpr: 0.1971\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25628\\2402510641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprob_0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#pred = None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\Huyunting_Huang\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\Huyunting_Huang\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\Huyunting_Huang\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\Huyunting_Huang\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Huyunting Huang\\Desktop\\EEG_Project\\util.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0meeg_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meeg_files\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0meeg_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meeg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDO_FFT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0meeg_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfft2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meeg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 441\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Frequency Domain\n",
    "best_val_acc = None\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    model.train()\n",
    "    count=0\n",
    "    prob_0=None\n",
    "    #pred = None\n",
    "    for data, label in train_loader:\n",
    "        data = data.float().to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim = 1)\n",
    "        curr_prob_0=output[:,0]\n",
    "\n",
    "        #curr_pred = output.argmax(dim = 1)\n",
    "        #if pred:\n",
    "        #    pred = torch.cat(curr_pred.cpu().numpy())\n",
    "      #  else:\n",
    "       #     pred = curr_pred\n",
    "      #  pred = pred.numpy()\n",
    "        \n",
    "        acc = (pred == label).float().mean()\n",
    "        #curr_tp_count = (pred == 1) and (label == 1)\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        tp_count=0\n",
    "        fp_count=0\n",
    "        tn_count=0\n",
    "        fn_count=0\n",
    "        prob_1=None\n",
    "        whole_label=None\n",
    "        #best_val_acc=0\n",
    "        for data, label in test_loader:\n",
    "            #print(data.shape)\n",
    "            data = data.float().to(device)\n",
    "            label = label.to(device)\n",
    "                        \n",
    "            val_output = model(data)\n",
    "            pred=val_output.argmax(dim=1)\n",
    "            val_loss = criterion(val_output, label)\n",
    "            tp_count+=torch.logical_and(pred == 1, label == 1).sum()\n",
    "            fp_count+=torch.logical_and(pred == 1, label == 0).sum()\n",
    "            tn_count+=torch.logical_and(pred == 0, label == 0).sum()\n",
    "            fn_count+=torch.logical_and(pred == 0, label == 1).sum()\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(test_loader)\n",
    "            epoch_val_loss += val_loss / len(test_loader)\n",
    "            #curr_pred = val_output.argmax(dim = 1)\n",
    "            curr_prob_1=val_output[:,1]\n",
    "            if prob_1 == None:\n",
    "                \n",
    "                prob_1=curr_prob_1\n",
    "            else:\n",
    "                prob_1=torch.cat((prob_1,curr_prob_1))\n",
    "            if whole_label==None:\n",
    "                \n",
    "                whole_label=label\n",
    "            else:\n",
    "                whole_label=torch.cat((whole_label,label))\n",
    "        tpr=tp_count/(tp_count+fn_count)\n",
    "        fpr=fp_count/(tn_count+fp_count)\n",
    "        #tn=tn_count/(tn_count+fp_count)\n",
    "        #fn=fn_count/(tn_count+fn_count)            \n",
    "        if best_val_acc:\n",
    "            if best_val_acc < epoch_val_accuracy:\n",
    "                best_val_acc = epoch_val_accuracy\n",
    "                torch.save(model,\"model_Frequency.pt\")\n",
    "                optm_tpr=tp_count/(tp_count+fn_count)\n",
    "                optm_fpr=fp_count/(tn_count+fp_count)\n",
    "                optm_true_label=whole_label.cpu().numpy()\n",
    "                optm_prob_1=prob_1.cpu().numpy()\n",
    "                #optm_tn=tn_count/(fp_count+tn_count)\n",
    "                #optm_fn=fn_count/(tn_count+fn_count)\n",
    "        else:\n",
    "            best_val_acc = epoch_val_accuracy\n",
    "            torch.save(model,\"model_Frequency.pt\")\n",
    "            optm_tpr=tp_count/(tp_count+fn_count)\n",
    "            optm_fpr=fp_count/(fp_count+tn_count)\n",
    "            #optm_tn=tn_count/(tn_count+fn_count)\n",
    "            optm_true_label=whole_label.cpu().numpy()\n",
    "            optm_prob_1=prob_1.cpu().numpy()            \n",
    "        print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\"\n",
    "    )\n",
    "    print(f\"tp : {tp_count} - fp : {fp_count} - tn: {tn_count} - fn : {fn_count} - tpr:{tpr:.4f}- fpr: {fpr:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
